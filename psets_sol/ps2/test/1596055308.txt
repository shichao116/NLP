In this path breaking contribution to the logic of probability,Keynes showed how to adapt the work of George Boole for the purpose of estimating probabilities.Keynes is the first scholar in history to explicitly emphasize the importance of interval estimates in decision making.For Keynes there are only two types of probability estimates,point estimates and interval estimates.Unfortunately,Keynes decided to call interval estimates "non-numerical"probabilities.His reasoning is really quite obvious.A precise estimate of probability used a single numeral for the point estimate.Therefore,an imprecise estimate of probability used two numerals to denote an interval(set).Thus, an interval estimate is not based on a single numeral but two. These types of probabilities are thus "non-numerical"because you are not using a single numeral.In 1922 and 1926,Frank Ramsey reviewed Keynes's book based on his reading of chapters 1-4 plus 3 pages from Part two and 4 pages from Part five.Keynes's discussion of non-numerical probabilities takes place in chapters 5,10,15 and 17.Keynes then applies his new approach to induction and analogy in chapters 20 and 22,using his concept of "finite probability"which applies to both precise numerical probabilities and imprecise non-numerical probabilities.All of Keynes's discoveries ,however,were ignored by the ignorant Ramsey.(To this day(2005)one can regularly read about Keynes's "strange,mysterious,unfathomable,undefined"non-numerical probabilities in literally hundreds of economics and philosophy journal articlesthat are based primarily  on Ramsey's reviews.These reviews are still cited as "overwhelming" evidence that Keynes agreed that Ramsey's critique had demolished the entire structure of his logical approach to probability.Nothing could be further from the truth.Ramsey's reviews were so poor that Keynes and Bertrand Russell attempted to downplay their relevance so as to save Ramsey from being embarrassed in the academic community.)Keynes then showed that interval estimates,because they overlap,would very likely also,in many cases,be noncomparable and/or nonrankable if a decision maker used such order preserving operators like"greater than or equal to"or "less than or equal to".While this is quite obvious,it went completely over Ramsey's head. Keynes's second major advance was to create his "conventional coefficient of weight and risk", c=p/(1+q)[2w/(1+w)]. The goal of the decision maker is to Maximize cA,where A is some outcome.This decision rule solves all of the paradoxes and anomalies that plague subjective expected utility theory.A major accomplishment made by Keynes in chapter 26 of the TP was to specify that the weight of the evidence variable,w,was defined on the unit interval [0,1].It would be forty years before Daniel Ellsberg would define his practically identical variable,rho,on the unit interval between 0 and 1 also,where rho measured the degree of confidence in the decision maker's information base.Since these two measures are one to one onto and isomorphic,Keynesian weight(uncertainty in the General Theory) and Ellsbergian ambiguity measure the same thing and are interchangeable.This means that Ellsberg's analysis can be applied when studying the GT and used to buttress Keynes's theory of liquidity preference in the GT.In Part 5 of this book ,Keynes showed how one could use Chebyshev's Inequality as a lower bound to the normal probability distributions overly precise point estimate . Part 5 of the Treatise also includes Keynes's advocacy of the Lexis Q test for stability of a statistical frequency[law of large numbers].It is this part of the TP that forms the basis,along with chapter 17,of Keynes's exchange with Tinbergen over the logical foundations of econometrics in the Economic Journal in 1939-1940.Keynes pointed out that ,in order to justify his assumption of normality,Tinbergen needed to apply the Lexis Q test.Tinbergen never applied either that test or the Chi- Square test for goodness of fit.This will then bring the reader back to Keynes's chapter 8 of the Treatise ,where he presents his own logical frequency interpretation of probability as a special case of his general logical approach to probability.