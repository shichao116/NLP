{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem set 5: Parsing\n",
    "===========\n",
    "\n",
    "This problem set contains two parts. \n",
    "\n",
    "- ** English Dependency parsing **: design features to learn a high-accuracy dependency parser for the English language\n",
    "- ** Multilingual Dependency Parsing **: design features to learn a high-accuracy dependency parser for a language other than english of your choice\n",
    "\n",
    "### Honor policy ###\n",
    "\n",
    "- Your work must be your own. Do not discuss the details of the assignment with other people. \n",
    "- You may of course help each other with understanding the ideas discussed in lecture and the readings, and with basic questions about programming in Python. It is **not acceptable** to discuss how to implement a specific feature for dependency parsing, and it is unacceptable to share your code.\n",
    "- There are implementations and source code for many machine learning algorithms on the internet. Please write the code for this assignment on your own, without using these external resources, except where noted (usually in the bakeoff only)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: English Dependency parsing #\n",
    "\n",
    "In this problem, you will work with an arc-factored non-projective dependency parser, which is trained by average perceptron. If you were not confident about your own implementation of averaged structure perceptron, please take a look at the code, in the directories shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<module 'gtparsing.dependency_parser' from 'gtparsing/dependency_parser.pyc'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from os.path import join\n",
    "import gtparsing\n",
    "import gtparsing.dependency_parser as depp\n",
    "import gtparsing.dependency_features as depf\n",
    "import gtparsing.custom_features\n",
    "import gtparsing.utilities\n",
    "from score import accuracy\n",
    "%pylab inline\n",
    "reload(depp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DIR = \"data/deppars/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtparsing/../data/deppars\n",
      "Number of sentences: 7569\n",
      "Number of tokens: 75621\n",
      "Number of words: 11766\n",
      "Number of pos: 48\n",
      "Number of features: 801\n"
     ]
    }
   ],
   "source": [
    "# build a dependency parser with a given feature set\n",
    "dp = depp.DependencyParser(feature_function=depf.DependencyFeatures())\n",
    "dp.read_data(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Train: 0.435 Dev: 0.427\n",
      "Epoch 2 Train: 0.440 Dev: 0.436\n",
      "Epoch 3 Train: 0.440 Dev: 0.453\n",
      "Epoch 4 Train: 0.441 Dev: 0.455\n",
      "Epoch 5 Train: 0.440 Dev: 0.456\n",
      "Epoch 6 Train: 0.440 Dev: 0.460\n",
      "Epoch 7 Train: 0.440 Dev: 0.462\n",
      "Epoch 8 Train: 0.442 Dev: 0.461\n",
      "Epoch 9 Train: 0.440 Dev: 0.464\n",
      "Epoch 10 Train: 0.441 Dev: 0.462\n"
     ]
    }
   ],
   "source": [
    "# train your parser for ten iterations\n",
    "# These are *unlabeled* accuracies.\n",
    "dp.train_perceptron(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "In file ```parsing/custom_features.py```, you are going to create a series of subclasses of ```DependencyFeatures```, which has features of your choice. We provide an example of one such class ```LexFeats```, which adds a feature that includes:\n",
    "\n",
    "- The part-of-speech of the head\n",
    "- The word of the modifier\n",
    "\n",
    "** Note ** - Please take a careful look at the documentation provided for the class. It should help you design the other classes for the subsequent deliverables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(gtparsing.custom_features)\n",
    "from gtparsing.custom_features import LexFeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtparsing/../data/deppars\n",
      "Number of sentences: 7569\n",
      "Number of tokens: 75621\n",
      "Number of words: 11766\n",
      "Number of pos: 48\n",
      "Number of features: 23019\n",
      "Epoch 1 Train: 0.488 Dev: 0.507\n"
     ]
    }
   ],
   "source": [
    "#let's run it\n",
    "dp = depp.DependencyParser(feature_function=LexFeats())\n",
    "dp.read_data(\"english\")\n",
    "dp.train_perceptron(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Deliverable 1a ** (3 points): start by adding a feature that computes the distance between the head and the modifier, up to a maximum absolute value of 10. To do this, implement the code for the class ```LexDistFeats``` in ```gtparsing.custom_features```\n",
    "\n",
    "**Sanity check**: you should now have 23039 features. Accuracy should improve substantially. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload(depp)\n",
    "reload (gtparsing.custom_features)\n",
    "from gtparsing.custom_features import LexDistFeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtparsing/../data/deppars\n",
      "Number of sentences: 7569\n",
      "Number of tokens: 75621\n",
      "Number of words: 11766\n",
      "Number of pos: 48\n",
      "Number of features: 23039\n",
      "Epoch 1 Train: 0.627 Dev: 0.626\n",
      "Epoch 2 Train: 0.678 Dev: 0.649\n",
      "Epoch 3 Train: 0.696 Dev: 0.664\n",
      "Epoch 4 Train: 0.710 Dev: 0.671\n",
      "Epoch 5 Train: 0.718 Dev: 0.680\n",
      "Epoch 6 Train: 0.729 Dev: 0.683\n",
      "Epoch 7 Train: 0.733 Dev: 0.690\n",
      "Epoch 8 Train: 0.739 Dev: 0.688\n",
      "Epoch 9 Train: 0.744 Dev: 0.690\n",
      "Epoch 10 Train: 0.752 Dev: 0.694\n",
      "Saved Output to data/deppars/deliverable1a.conll\n"
     ]
    }
   ],
   "source": [
    "dp = depp.DependencyParser(feature_function=LexDistFeats())\n",
    "dp.read_data(\"english\")\n",
    "dp.train_perceptron(10)\n",
    "dp.test(join (DIR, \"english_dev.conll\"), join (DIR, \"deliverable1a.conll\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Deliverable 1b ** (3 points): now add a feature to LexDistFeats, which includes the POS of the modifier and the word of the head. To do this, implement the code for the class ```LexDistFeats2``` in ```gtparsing.custom_features```\n",
    "\n",
    "**Sanity check**: The number of features should roughly double. (Do you see why?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload (gtparsing.custom_features)\n",
    "from gtparsing.custom_features import LexDistFeats2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtparsing/../data/deppars\n",
      "Number of sentences: 7569\n",
      "Number of tokens: 75621\n",
      "Number of words: 11766\n",
      "Number of pos: 48\n",
      "Number of features: 44546\n",
      "Epoch 1 Train: 0.649 Dev: 0.661\n",
      "Epoch 2 Train: 0.722 Dev: 0.684\n",
      "Epoch 3 Train: 0.755 Dev: 0.691\n",
      "Epoch 4 Train: 0.779 Dev: 0.694\n",
      "Epoch 5 Train: 0.798 Dev: 0.708\n",
      "Epoch 6 Train: 0.811 Dev: 0.709\n",
      "Epoch 7 Train: 0.821 Dev: 0.715\n",
      "Epoch 8 Train: 0.833 Dev: 0.724\n",
      "Epoch 9 Train: 0.838 Dev: 0.724\n",
      "Epoch 10 Train: 0.846 Dev: 0.729\n",
      "Saved Output to data/deppars/deliverable1b.conll\n"
     ]
    }
   ],
   "source": [
    "dp = depp.DependencyParser(feature_function=LexDistFeats2())\n",
    "dp.read_data(\"english\")\n",
    "dp.train_perceptron(10)\n",
    "dp.test(join (DIR, \"english_dev.conll\"), join (DIR, \"deliverable1b.conll\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context features ## \n",
    "\n",
    "Add context features that consider the tags adjacent to the head and modifier. You may wish to consider various tag combinations, such as \n",
    "\n",
    " - $\\langle t[h], t[h-1], t[m]\\rangle$: head, head-left, modifier\n",
    " - $\\langle t[h], t[m], t[m+1]\\rangle$: head, modifier, modifier-right\n",
    " - $\\langle t[h], t[h-1], t[m], t[m+1]\\rangle$: head, head-left, modifier, modifier-right\n",
    " - etc\n",
    "\n",
    "Note that you can add more than one feature at a time within ```create_arc_features()```. Watch out for edge cases!\n",
    "\n",
    "** Deliverable 1c ** (5 points):\n",
    "\n",
    "Describe what context feature templates you have added. How do they impact the total number of features? How does \n",
    "it impact the development and training accuracy?\n",
    "\n",
    "** Note **- You must atleast add head, head-left, modifier feature\n",
    "\n",
    "To do this, implement the code for the class ```ContextFeats``` in ```gtparsing.custom_features```\n",
    "\n",
    "** Sanity check **: I added a few basic context features, and this increased dev set accuracy above 82%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload (gtparsing.custom_features)\n",
    "from gtparsing.custom_features import ContextFeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtparsing/../data/deppars\n",
      "Number of sentences: 7569\n",
      "Number of tokens: 75621\n",
      "Number of words: 11766\n",
      "Number of pos: 48\n",
      "Number of features: 65753\n",
      "Epoch 1 Train: 0.745 Dev: 0.793\n",
      "Epoch 2 Train: 0.815 Dev: 0.810\n",
      "Epoch 3 Train: 0.841 Dev: 0.817\n",
      "Epoch 4 Train: 0.862 Dev: 0.823\n",
      "Epoch 5 Train: 0.877 Dev: 0.830\n",
      "Epoch 6 Train: 0.888 Dev: 0.829\n",
      "Epoch 7 Train: 0.898 Dev: 0.829\n",
      "Epoch 8 Train: 0.903 Dev: 0.831\n",
      "Epoch 9 Train: 0.910 Dev: 0.833\n",
      "Epoch 10 Train: 0.916 Dev: 0.833\n",
      "Saved Output to data/deppars/deliverable1c.conll\n"
     ]
    }
   ],
   "source": [
    "dp = depp.DependencyParser(feature_function=ContextFeats())\n",
    "dp.read_data(\"english\")\n",
    "dp.train_perceptron(10)\n",
    "dp.test(join (DIR, \"english_dev.conll\"), join (DIR, \"deliverable1c.conll\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add your response to Deliverable 1c here\n",
    "### Answer to 1c ###\n",
    "- I added all the three context features mentioned above:\n",
    " - $\\langle t[h], t[h-1], t[m]\\rangle$: head, head-left, modifier\n",
    " - $\\langle t[h], t[m], t[m+1]\\rangle$: head, modifier, modifier-right\n",
    " - $\\langle t[h], t[h-1], t[m], t[m+1]\\rangle$: head, head-left, modifier, modifier-right\n",
    " \n",
    "- These three types of feature increased the size of all features by half of that of LexDistFeats2\n",
    "- They improve the training accuracy to 91.6% and development accuracy to 83.3%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bakeoff! ##\n",
    "\n",
    "Similar to the previous problem sets, we will have a kaggle competition for this problem set. Two days before the submission, we will release a test data set. Try to develop other features that will further improve performance. Please explain all the features that you have. We will provide the submission function through piazza.\n",
    "\n",
    "After identifying your best feature set, run *test()* function from DependencyParser. Please name the file as **lastname-firstname.conll.pred**.\n",
    "\n",
    "**Deliverable 1d** (4 points): Explain why the features you added would work and include your response file in your t-square submission.\n",
    "\n",
    "**Sanity check / challenge**: The best test set performance in Fall 2014 was 86.5%. Can you beat it??\n",
    "\n",
    "**NOTE**: As usual, you are not supposed to look at other code online while doing this problem set. However, you are welcome to search for *research papers* on dependency parsing to get ideas for features that might improve your performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to 1d ###\n",
    "I used the feature set defined by ```ContextFeats``` in part 1c. As stated in the answer to 1c, I added context features of adjacent pos tags of head and modifier. \n",
    "    \n",
    "These features couple the phrase structural information, as used in HMM algorithm, into other lexical features. POS tag phrase structure can provide significantly more information to remove the disambiguity in some cases. Especially when determining which word is head and which word is modifier, these features are very effective. For example normally if we have a verb followed by a noun, the verb is much more likely to the head, which can be well captured by POS tags of adjacents words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Uncomment the line below and modify it so that the filename is lastname-firstname.conll.pred\n",
    "DELIVERABLE1d = join (DIR, \"shi-chao.conll.pred\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved Output to data/deppars/shi-chao.conll.pred\n"
     ]
    }
   ],
   "source": [
    "# run this when you have trained on your best features. \n",
    "dp.test(join (DIR, \"english_test.conll\"), DELIVERABLE1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Multilingual Dependency parsing #\n",
    "\n",
    "In this part, you will do a series of tasks:\n",
    "\n",
    "- **Delexicalized direct transfer learning**. This means training a parser without lexical features, and directly porting it to another languag, without retraining.\n",
    "- Retrain the delexicalized parser in the target language.\n",
    "- Train a lexicalized parser in the target language.\n",
    "\n",
    "** Note ** - Running each part of this section can be slow, so make sure you start early if you want to finish in time.\n",
    "\n",
    "First, you choose which target language you want to work with. Uncomment the line from the following cell depending on the language you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TARGET_LANGUAGE = \"german\"\n",
    "TARGET_LANGUAGE = \"french\"\n",
    "#TARGET_LANGUAGE = \"italian\"\n",
    "#TARGET_LANGUAGE = \"spanish\"\n",
    "#TARGET_LANGUAGE = \"portuguese\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get us started, we warmup by comparing the probability distributions of part of speech tags for two different datasets.\n",
    "\n",
    "- In part 1, you used the dataset identified by \"english\" language. \n",
    "- The same data is also available for \"english_univtags\" language. \n",
    "- The difference is in the size of the tagset, where the size is smaller in english_univtags. The tagset is chosen such that it has _universal_ applicability to multiple languages. Effectively, the tagging is much more coarse grained in english_univtags than in english.\n",
    "\n",
    "** Deliverable 2a ** (3 points): Calculate the conditional probability distribution of modifier PoS tag given head PoS tag i.e $P(\\text{modifier tag}=n \\mid \\text{head tag}=m), \\forall n \\in T$, where $T$ is the tagset.  In order to do this, implement the ```CPT``` function in ```gtparsing.utilities```, which should take as arguments a list of instances and the tag index representing the head of a dependency relation, and should return a dict of probabilities of the tags of the modifiers.\n",
    "\n",
    "Use this function to calculate the conditional probability distributions where the head tag is verb for \"english\" and \"english_univtags\" datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload (gtparsing.utilities)\n",
    "from gtparsing.utilities import CPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtparsing/../data/deppars\n",
      "Number of sentences: 7569\n",
      "Number of tokens: 75621\n",
      "Number of words: 11766\n",
      "Number of pos: 48\n",
      "Number of features: 801\n"
     ]
    }
   ],
   "source": [
    "dp = depp.DependencyParser(feature_function=depf.DependencyFeatures())\n",
    "dp.read_data(\"english\")\n",
    "eng_tag_dist = CPT(dp.reader.train_instances, dp.reader.pos_dict[\"VB\"])\n",
    "eng_reverse_lookup = {value:key for key,value in dp.reader.pos_dict.iteritems()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtparsing/../data/deppars\n",
      "Number of sentences: 7569\n",
      "Number of tokens: 75621\n",
      "Number of words: 11766\n",
      "Number of pos: 15\n",
      "Number of features: 142\n"
     ]
    }
   ],
   "source": [
    "dp = depp.DependencyParser(feature_function=depf.DependencyFeatures())\n",
    "dp.read_data(\"english_univtags\")\n",
    "eng_univ_tag_dist = CPT(dp.reader.train_instances, dp.reader.pos_dict[\"VERB\"])\n",
    "eng_univ_reverse_lookup = {value:key for key,value in dp.reader.pos_dict.iteritems()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code plots the distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_dist (values, labels):\n",
    "    WIDTH = 0.35\n",
    "    f = figure (figsize = (10,5))\n",
    "    ax = f.add_subplot (111)\n",
    "    ax.bar (np.arange (len(values)),values)\n",
    "    xticks (np.arange (len (values)) + WIDTH, labels, rotation=45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAE+CAYAAACk3eW2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUQUAMICoAgAYQFQBAAwgqgAABvg/Mx0xGf79ZjMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f11640bb950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlUAAAFHCAYAAACI8Lm/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1155414150>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_dist (eng_tag_dist.values(), [eng_reverse_lookup[tag_index] for tag_index in eng_tag_dist.keys()[0]])\n",
    "plot_dist (eng_univ_tag_dist.values(), [eng_univ_reverse_lookup[tag_index] for tag_index in eng_univ_tag_dist.keys()[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Deliverable 2b ** (3 points) : Now calculate the [entropy](https://en.wikipedia.org/wiki/Entropy_(information_theory) of each of the distribution. How are the two distributions different? \n",
    "\n",
    "In order to do this, you will implement ```entropy``` function ```gtparsing.utilities``` module "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reload (gtparsing.utilities)\n",
    "from gtparsing.utilities import entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.82695524612\n",
      "-2.74125094813\n"
     ]
    }
   ],
   "source": [
    "print entropy (eng_tag_dist)\n",
    "print entropy (eng_univ_tag_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Deliverable 2c ** (3 points) Implement ```DelexicalizedFeats``` in ```gtparsing/custom_features```. You should have the following features:\n",
    "\n",
    "- part of speech tag of the head and modifier pair\n",
    "- distance between the head and the modifier upto a maximum absolute value of 10\n",
    "\n",
    "Train the dependency parser on ** english_univtags ** and transfer learning to the target language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reload (gtparsing.custom_features)\n",
    "from gtparsing.custom_features import DelexicalizedFeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtparsing/../data/deppars\n",
      "Number of sentences: 7569\n",
      "Number of tokens: 75621\n",
      "Number of words: 11766\n",
      "Number of pos: 15\n",
      "Number of features: 874\n",
      "Epoch 1 Train: 0.668 Dev: 0.695\n",
      "Epoch 2 Train: 0.673 Dev: 0.707\n",
      "Epoch 3 Train: 0.674 Dev: 0.699\n",
      "Epoch 4 Train: 0.674 Dev: 0.706\n",
      "Epoch 5 Train: 0.672 Dev: 0.703\n",
      "Epoch 6 Train: 0.674 Dev: 0.705\n",
      "Epoch 7 Train: 0.674 Dev: 0.708\n",
      "Epoch 8 Train: 0.674 Dev: 0.710\n",
      "Epoch 9 Train: 0.675 Dev: 0.705\n",
      "Epoch 10 Train: 0.673 Dev: 0.702\n",
      "Saved Output to data/deppars/french.deliverable2c.conll\n",
      "Accuracy: 0.489772490086\n",
      "0.489772490086\n"
     ]
    }
   ],
   "source": [
    "# training on english\n",
    "dp = depp.DependencyParser(feature_function=DelexicalizedFeats())\n",
    "dp.read_data(\"english_univtags\")\n",
    "dp.train_perceptron(10)\n",
    "dp.test(join (DIR, TARGET_LANGUAGE+\"_dev.conll\"), join (DIR, TARGET_LANGUAGE + \".deliverable2c.conll\"))\n",
    "print \"Accuracy:\", accuracy(join (DIR, TARGET_LANGUAGE+\"_dev.conll\"), join (DIR, TARGET_LANGUAGE + \".deliverable2c.conll\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Deliverable 2d **(3 points) Train the delexicalized parser in the target language. \n",
    "\n",
    "* Find the worst predicted label i.e the label for which the parser makes the most mistakes.\n",
    "* Find the best predicted label ie. the label for which the parser makes the least mistakes,\n",
    "\n",
    "In order to do this you may want to compare the predictions to the true labels by calculating the [confusion matrix](https://en.wikipedia.org/wiki/Confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtparsing/../data/deppars\n",
      "Number of sentences: 14511\n",
      "Number of tokens: 351233\n",
      "Number of words: 41385\n",
      "Number of pos: 14\n",
      "Number of features: 1260\n",
      "Epoch 1 Train: 0.596 Dev: 0.580\n",
      "Epoch 2 Train: 0.600 Dev: 0.581\n",
      "Epoch 3 Train: 0.599 Dev: 0.612\n",
      "Epoch 4 Train: 0.600 Dev: 0.602\n",
      "Epoch 5 Train: 0.599 Dev: 0.601\n",
      "Epoch 6 Train: 0.600 Dev: 0.601\n",
      "Epoch 7 Train: 0.600 Dev: 0.596\n",
      "Epoch 8 Train: 0.599 Dev: 0.596\n",
      "Epoch 9 Train: 0.599 Dev: 0.596\n",
      "Epoch 10 Train: 0.598 Dev: 0.598\n",
      "Saved Output to data/deppars/french.deliverable2d.conll\n"
     ]
    }
   ],
   "source": [
    "dp = depp.DependencyParser(feature_function=DelexicalizedFeats())\n",
    "dp.read_data(TARGET_LANGUAGE)\n",
    "dp.train_perceptron(10)\n",
    "dp.test(join (DIR, TARGET_LANGUAGE+\"_dev.conll\"), join (DIR, TARGET_LANGUAGE + \".deliverable2d.conll\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer to 2d: ###\n",
    " - The cell below computes the confusion matrix and finds the top 10 worst predicted labels and top 18 best predicted label. Because there 18 labels that only makes one mistake.\n",
    " - From the last two print statements we see that the top 3 worst predicted(in terms of number of errors rather than the error rate) label is NOUN tagged as VERB, VERB being tagged as NOUN, and VERB tagged as ADP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('NOUN', 'VERB'), 2274), (('VERB', 'NOUN'), 1868), (('VERB', 'ADP'), 857), (('NOUN', 'ADP'), 812), (('NOUN', '.'), 630), (('ADP', 'NOUN'), 613), (('VERB', '.'), 600), (('ADP', 'VERB'), 460), (('ADJ', 'NOUN'), 152), (('ADJ', 'VERB'), 149)]\n",
      "[(('ADJ', 'PRT'), 1), (('CONJ', 'PRON'), 1), (('PRON', 'ADV'), 1), (('CONJ', 'ADJ'), 1), (('CONJ', 'X'), 1), (('NUM', 'X'), 1), (('PRT', 'X'), 1), (('PRT', 'ADJ'), 1), (('.', 'ADV'), 1), (('NUM', 'ADJ'), 1), (('X', 'ADV'), 1), (('VERB', 'DET'), 1), (('PRON', 'DET'), 1), (('DET', 'NUM'), 1), (('ADJ', 'PRON'), 1), (('.', 'PRT'), 1), (('ADV', '.'), 1), (('ADV', 'X'), 1)]\n"
     ]
    }
   ],
   "source": [
    "f_dev = open(DIR+TARGET_LANGUAGE+'_dev.conll')\n",
    "ddevs = []\n",
    "ddev = []\n",
    "for line in f_dev:\n",
    "    if len(line.split()) == 0:\n",
    "        ddevs.append(np.array([np.array(ddev)[:,3],np.array(ddev)[:,6]]))\n",
    "        ddev = []\n",
    "        continue\n",
    "    ddev.append(line.split())\n",
    "f_dev.close()\n",
    "\n",
    "f_prd = open(DIR+TARGET_LANGUAGE+'.deliverable2d.conll')\n",
    "dprds = []\n",
    "dprd = []\n",
    "for line in f_prd:\n",
    "    if len(line.split()) == 0:\n",
    "        dprds.append(np.array([np.array(dprd)[:,3],np.array(dprd)[:,6]]))\n",
    "        dprd = []\n",
    "        continue\n",
    "    dprd.append(line.split())\n",
    "f_prd.close()\n",
    "\n",
    "htag_dev = []\n",
    "htag_prd = []\n",
    "def dec1(x):\n",
    "    return x-1\n",
    "for i in range(len(ddevs)):\n",
    "    htag_dev.append(np.array(ddevs[i][0,:][map(dec1,map(int,ddevs[i][1,:]))]))\n",
    "    htag_prd.append(np.array(dprds[i][0,:][map(dec1,map(int,dprds[i][1,:]))]))\n",
    "\n",
    "from collections import Counter\n",
    "confusion = Counter()                  # confusion matrix, here I only count the number of errors, which means\n",
    "for i in range(len(htag_dev)):         # I use the number of errors of a tag instead of accuracy as a measure.\n",
    "    if np.any(htag_dev[i] != htag_prd[i]):\n",
    "        ierrs = np.where(htag_dev[i]!=htag_prd[i])[0]\n",
    "        for ierr in ierrs:\n",
    "            confusion[(htag_dev[i][int(ierr)],htag_prd[i][int(ierr)])] += 1\n",
    "import operator\n",
    "# print worst predicted and best predicted labels.\n",
    "print sorted(confusion.items(), key=operator.itemgetter(1))[-10:][::-1]\n",
    "print sorted(confusion.items(), key=operator.itemgetter(1))[:18]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deliverable 2e** (3 points) Now train the parser for 10 iterations by adding lexical features. You should also use the delexicalized and distance features. Explain the following:\n",
    "\n",
    "* Have the mistakes for the worst predicted label from 2d gone down? \n",
    "* Give top 3 worst predicted labels and top 3 best predicted labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gtparsing/../data/deppars\n",
      "Number of sentences: 14511\n",
      "Number of tokens: 351233\n",
      "Number of words: 41385\n",
      "Number of pos: 14\n",
      "Number of features: 60820\n",
      "Epoch 1 Train: 0.634 Dev: 0.626\n",
      "Epoch 2 Train: 0.647 Dev: "
     ]
    }
   ],
   "source": [
    "reload(gtparsing.custom_features)\n",
    "from gtparsing.custom_features import RelexicalizedFeats\n",
    "dp = depp.DependencyParser(feature_function=RelexicalizedFeats()) # Make appropriate call here\n",
    "dp.read_data(TARGET_LANGUAGE)\n",
    "dp.train_perceptron(10)\n",
    "dp.test(join (DIR, TARGET_LANGUAGE+\"_dev.conll\"), join (DIR, TARGET_LANGUAGE + \".deliverable2e.conll\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Deliverable 2f** (6 points) Train the parser for 10 iterations to improve the accuracy of the parser by at least 3%. Include at least one context feature and one morphological feature. The morphological features should access the words themselves; this is possible using the ```self.word_dict``` member variable of ```dependency_features```. Try to include more than one feature of each kind. Explain what features you added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dp = depp.DependencyParser(feature_function=) # Make appropriate call here\n",
    "dp.read_data(TARGET_LANGUAGE)\n",
    "dp.train_perceptron(10)\n",
    "dp.test(join (DIR, TARGET_LANGUAGE+\"_dev.conll\"), join (DIR, TARGET_LANGUAGE + \".deliverable2f.conll\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: 7650 Only #\n",
    "\n",
    "- This is more research-oriented than in previous assignments. Be prepared to read and to think!\n",
    "- [Hohensee and Bender](http://aclweb.org/anthology/N/N12/N12-1032.pdf) show that features measuring morphological  agreement can significantly improve dependency parsing.\n",
    "- For your target language, read about morphology in your chosen target language.\n",
    "- Design a set of features that capture morphological agreement between the head and the modifier. These features can condition on the part-of-speech, but they need to take the morphology into account too. For example, in English, you might want to capture subject-verb agreement. To do this you could design the following features:\n",
    "    - < pos(h) = V, pos(m) = N, head verb is third-person singular, modifier noun is third-person singular>\n",
    "    - < pos(h) = V, pos(m) = N, head verb is not third-person singular, modifier noun is plural>\n",
    "    - etc\n",
    "- In the example above, you could use simple morphology to distinguish whether the noun is plural and whether the verb agrees, for example by checking for 's' at the end of each word.\n",
    "- If you can find existing resources (dictionaries or code) that capture morphology of interest for your targeted language, you may use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Deliverable 3** (8 points) \n",
    "\n",
    "- Explain the morphological agreement that your features are trying to capture.\n",
    "- Explain how you try to implement morphological agreement as a feature.\n",
    "- Test whether your feature improves performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
